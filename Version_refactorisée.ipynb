{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Version refactorisée.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNo5Zi/PIOzWDCd/I1IMuS/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RomainHerault/PRD/blob/master/Version_refactoris%C3%A9e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiAbHSrRDQMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5736193a-057b-4e03-ff60-f1d74a0fa696"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujOCewBP6cNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "import datetime\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import re\n",
        "import torch.nn.functional as F\n",
        "from fluideDataset import fluideDataset\n",
        "from R2Plus1D import R2Plus1DClassifier\n",
        "\n",
        "class Classifier:\n",
        "  def __init__(self, number_classes):\n",
        "    self.model = R2Plus1DClassifier(number_classes, (2, 2, 2, 2), pretrained=False).cuda()\n",
        "\n",
        "  def load_model(self, path_model=None):\n",
        "    if path_model is not None and os.path.exists(path_model):\n",
        "      print('Pretrained Model existed')\n",
        "      bestModelWts = torch.load(path_model)\n",
        "      self.model.load_state_dict(bestModelWts)\n",
        "    else:\n",
        "      print(\"Le modèle n'est pas entraîné\")\n",
        "      bestModelWts = copy.deepcopy(self.model.state_dict()) # Copier les paramètres initiaux du modèle \n",
        "\n",
        "  def batch_predict(self, clip):\n",
        "      outputs = self.model(clip.cuda().float())\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "      return probs.detach().cpu().numpy()\n",
        "\n",
        "class Input_processing:\n",
        "  def __init__(self, video_path):\n",
        "    self.video_path = video_path\n",
        "\n",
        "  def store_video_in_one_folder(self, number_images):\n",
        "    numImages = 0\n",
        "    path = self.video_path\n",
        "    self.temp_video_folder = os.path.basename(path)+\"_video\"\n",
        "    if not os.path.isdir(self.temp_video_folder):\n",
        "      os.mkdir(self.temp_video_folder)\n",
        "    sub_folders = [f.path for f in os.scandir(path) if f.is_dir()]\n",
        "    sub_folders.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "    for filepath in (sub_folders):\n",
        "      numFolder = int(os.path.basename(filepath))\n",
        "      files = os.listdir(filepath)\n",
        "      files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "      for filename in files:\n",
        "        base, extension = os.path.splitext(filename)\n",
        "        num_file = numFolder * 30 + int(base)\n",
        "        if(numImages<num_file):\n",
        "          numImages = num_file\n",
        "        new_name =  os.path.join(self.temp_video_folder,  str(num_file)+extension)\n",
        "        shutil.copy(os.path.join(filepath,filename), new_name)\n",
        "        if num_file + 1 >= number_images:\n",
        "          return self.temp_video_folder\n",
        "    return self.temp_video_folder\n",
        "\n",
        "  def calcDoG(image):\n",
        "    dogImg = np.empty((image.shape[0],image.shape[1],0))\n",
        "    dog1 = -cv2.GaussianBlur(image,(0,0),scaleFactor[0])+image\n",
        "    dog1[dog1<0]=0\n",
        "    dog1 = np.expand_dims(dog1,axis = 2)\n",
        "    dogImg = dogImg = np.concatenate((dogImg,dog1),axis = 2)\n",
        "    for k in range(len(scaleFactor)-1):\n",
        "      blur1 = cv2.GaussianBlur(image,(0,0),scaleFactor[k])\n",
        "      blur2 = cv2.GaussianBlur(image,(0,0),scaleFactor[k+1])\n",
        "      tempDoG = blur1 - blur2 \n",
        "      tempDoG[tempDoG<0]=0\n",
        "      tempDoG = np.expand_dims(tempDoG,axis = 2)\n",
        "      dogImg = np.concatenate((dogImg,tempDoG),axis = 2)\n",
        "    return dogImg\n",
        "\n",
        "  def convert_folder_to_clip(videoFolder, seqLength):\n",
        "    \"\"\"\n",
        "    Convert the png files to a clip\n",
        "    videoFolder : the folder that contains all the png files\n",
        "    seqLength : the number of images we want to take to create the clip \n",
        "    (the function takes the first n images)\n",
        "    \"\"\"\n",
        "    filenames = []\n",
        "    for filename in os.listdir(videoFolder):\n",
        "      base, extension = os.path.splitext(filename)\n",
        "      filenames.append(int(base))\n",
        "    filenames.sort()\n",
        "    clip = np.empty((0,96,256,5))\n",
        "    for img_num in filenames :\n",
        "      image = cv2.imread(videoFolder+\"/\"+str(img_num)+extension,0).astype(np.float64)/255.0\n",
        "      image = cv2.resize(image, (256,96),interpolation=cv2.INTER_AREA)\n",
        "      dogImg = Input_proccessing.calcDoG(image)\n",
        "      dogImg = np.expand_dims(dogImg,axis = 0)\n",
        "      clip = np.concatenate((clip,dogImg),axis = 0)\n",
        "      if(img_num == seqLength):\n",
        "        break\n",
        "    clip = torch.from_numpy(np.array(clip.transpose([3,0,1,2])))\n",
        "    print(clip.shape)\n",
        "    return clip.unsqueeze(0)\n",
        "\n",
        "  #print(batch_predict(convertFolderToClip(tempVideoFolder,15)))\n",
        "\n",
        "  def convert_images_to_clip(images_list):\n",
        "    \"\"\"\n",
        "    Convert the images files to a clip\n",
        "    videoFolder : the folder that contains all the png files\n",
        "    seqLength : the number of images we want to take to create the clip \n",
        "    (the function takes the first n images)\n",
        "    \"\"\"\n",
        "    clip = np.empty((0,96,256,5))\n",
        "    for image in images_list :\n",
        "      image =  image.astype(np.float64)/255.0\n",
        "      image = cv2.resize(image, (256,96),interpolation=cv2.INTER_AREA)\n",
        "      dogImg = Input_processing.calcDoG(image)\n",
        "      dogImg = np.expand_dims(dogImg,axis = 0)\n",
        "      clip = np.concatenate((clip,dogImg),axis = 0)\n",
        "    clip = torch.from_numpy(np.array(clip.transpose([3,0,1,2])))\n",
        "    return clip.unsqueeze(0)\n",
        "\n",
        "  def create_images(self):\n",
        "    images_list = []#liste des segments de chaque image\n",
        "    #Pour chaque image du dossier\n",
        "    for f in os.listdir(self.temp_video_folder) :\n",
        "      im = cv2.imread(self.temp_video_folder+\"/\"+f,0)\n",
        "      images_list.append(im)\n",
        "    return images_list\n",
        "\n",
        "class Segmentation:\n",
        "  installed = False\n",
        "  def __init__(self):\n",
        "    if not Segmentation.installed:\n",
        "      !apt-get install build-essential cmake libboost-all-dev\n",
        "      !git clone https://github.com/davidstutz/hierarchical-graph-based-video-segmentation.git\n",
        "      !pwd\n",
        "      %cd hierarchical-graph-based-video-segmentation\n",
        "      !pwd\n",
        "      !mkdir build\n",
        "      %cd build\n",
        "      !pwd\n",
        "      !cmake ..\n",
        "      !make\n",
        "      %cd ..\n",
        "      %cd ..\n",
        "      Segmentation.installed = True\n",
        "\n",
        "  def segment_images(self, video_folder):\n",
        "    temp_flow_folder = os.path.basename(video_folder)+\"_flow\"\n",
        "    if not os.path.isdir(temp_flow_folder):\n",
        "      os.mkdir(temp_flow_folder)\n",
        "      temp_out_folder = os.path.basename(video_folder)+\"_out\"\n",
        "      if not os.path.isdir(temp_out_folder):\n",
        "        os.mkdir(temp_out_folder)\n",
        "      self.temp_vis_folder = os.path.basename(video_folder)+\"_vis\"\n",
        "      if not os.path.isdir(self.temp_vis_folder) :\n",
        "        os.mkdir(self.temp_vis_folder)\n",
        "      num_images = os.listdir(video_folder)\n",
        "      !./hierarchical-graph-based-video-segmentation/build/optical_flow_cli/optical_flow_cli --input-dir '$video_folder' --output-dir $temp_flow_folder\n",
        "      !rm /content/$video_folder/0.png\n",
        "      !./hierarchical-graph-based-video-segmentation/build/segment_cli/segment_cli '$video_folder' $temp_flow_folder --length $num_images --hierarchies 50 --vis-dir $self.temp_vis_folder --output-dir $temp_out_folder --input-gt \"\"\n",
        "  \n",
        "  def get_segments(self, segmentation_hierarchie):\n",
        "    visualisation_folder = self.temp_vis_folder+'/'+str(segmentation_hierarchie)\n",
        "    dico = dict()\n",
        "    current_label = 0\n",
        "    segments_list = []#liste des segments de chaque image\n",
        "    #un segment = tableau de la taille de l'image contenant\n",
        "    #le label du segmentu pour chaque pixel\n",
        "\n",
        "    #Pour chaque image du dossier\n",
        "    for f in os.listdir(visualisation_folder) :\n",
        "      im = cv2.imread(visualisation_folder+\"/\"+f)\n",
        "      #On créé un segment en labélisant les couleurs de l'image\n",
        "      segment = np.zeros((im.shape[0], im.shape[1]))\n",
        "      for x in range(im.shape[0]):\n",
        "        for y in range(im.shape[1]):\n",
        "          couleur = tuple(im[x,y])\n",
        "          if (couleur not in dico):\n",
        "            current_label += 1\n",
        "            dico[couleur] = current_label\n",
        "          segment[x,y] = dico[couleur]\n",
        "      segments_list.append(segment)\n",
        "    self.nb_segments = current_label\n",
        "    return segments_list\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io6FSOocFJ2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install lime\n",
        "\n",
        "from lime import lime_image\n",
        "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\"\"\"\n",
        "Functions for explaining classifiers that use Video data.\n",
        "\"\"\"\n",
        "import copy\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.preprocessing\n",
        "from sklearn.utils import check_random_state\n",
        "from skimage.color import gray2rgb, rgb2gray\n",
        "from progressbar import ProgressBar\n",
        "from lime import lime_base\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "\n",
        "class VideoExplanation(object):\n",
        "    def __init__(self, images, segments):\n",
        "        \"\"\"Init function.\n",
        "\n",
        "        Args:\n",
        "            image: 3d numpy array\n",
        "            segments: 2d numpy array, with the output from skimage.segmentation\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "        self.segments = segments\n",
        "        self.intercept = {}\n",
        "        self.local_exp = {}\n",
        "        self.local_pred = None\n",
        "\n",
        "    def get_images_and_masks(self, label, positive_only=True, negative_only=False, hide_rest=False,\n",
        "                           num_features=5, min_weight=0.):\n",
        "        \"\"\"Init function.\n",
        "\n",
        "        Args:\n",
        "            label: label to explain\n",
        "            positive_only: if True, only take superpixels that positively contribute to\n",
        "                the prediction of the label.\n",
        "            negative_only: if True, only take superpixels that negatively contribute to\n",
        "                the prediction of the label. If false, and so is positive_only, then both\n",
        "                negativey and positively contributions will be taken.\n",
        "                Both can't be True at the same time\n",
        "            hide_rest: if True, make the non-explanation part of the return\n",
        "                image gray\n",
        "            num_features: number of superpixels to include in explanation\n",
        "            min_weight: minimum weight of the superpixels to include in explanation\n",
        "\n",
        "        Returns:\n",
        "            (image, mask), where image is a 3d numpy array and mask is a 2d\n",
        "            numpy array that can be used with\n",
        "            skimage.segmentation.mark_boundaries\n",
        "        \"\"\"\n",
        "        if label not in self.local_exp:\n",
        "            raise KeyError('Label not in explanation')\n",
        "        if positive_only & negative_only:\n",
        "            raise ValueError(\"Positive_only and negative_only cannot be true at the same time.\")\n",
        "        segments = self.segments\n",
        "        images = self.images\n",
        "        exp = self.local_exp[label]\n",
        "        temps = []\n",
        "        masks = []\n",
        "        for i in range(len(images)):\n",
        "          image = images[i]\n",
        "          segment = segments[i]\n",
        "          mask = np.zeros(segment.shape, dtype=int)\n",
        "          if hide_rest:\n",
        "              temp = np.zeros(image.shape)\n",
        "          else:\n",
        "              temp = image.copy()\n",
        "          if positive_only:\n",
        "              fs = [x[0] for x in exp\n",
        "                    if x[1] > 0 and x[1] > min_weight][:num_features]\n",
        "          if negative_only:\n",
        "              fs = [x[0] for x in exp\n",
        "                    if x[1] < 0 and abs(x[1]) > min_weight][:num_features]\n",
        "          if positive_only or negative_only:\n",
        "              for f in fs:\n",
        "                  temp[segment == f] = image[segment == f].copy()\n",
        "                  mask[segment == f] = 1\n",
        "              temps.append(temp)\n",
        "              masks.append(mask)\n",
        "          else:\n",
        "              for f, w in exp[:num_features]:\n",
        "                  if np.abs(w) < min_weight:\n",
        "                      continue\n",
        "                  c = 0 if w < 0 else 1\n",
        "                  mask[segment == f] = -1 if w < 0 else 1\n",
        "                  temp[segment == f] = image[segment == f].copy()\n",
        "                  temp[segment == f, c] = np.max(image)\n",
        "              temps.append(temp)\n",
        "              masks.append(mask)\n",
        "        return temps, masks\n",
        "\n",
        "\n",
        "class LimeVideoExplainer(object):\n",
        "    \"\"\"Explains predictions on Image (i.e. matrix) data.\n",
        "    For numerical features, perturb them by sampling from a Normal(0,1) and\n",
        "    doing the inverse operation of mean-centering and scaling, according to the\n",
        "    means and stds in the training data. For categorical features, perturb by\n",
        "    sampling according to the training distribution, and making a binary\n",
        "    feature that is 1 when the value is the same as the instance being\n",
        "    explained.\"\"\"\n",
        "\n",
        "    def __init__(self, kernel_width=.25, kernel=None, verbose=False,\n",
        "                 feature_selection='auto', random_state=None):\n",
        "        \"\"\"Init function.\n",
        "        \n",
        "        Args:\n",
        "            kernel_width: kernel width for the exponential kernel.\n",
        "            If None, defaults to sqrt(number of columns) * 0.75.\n",
        "            kernel: similarity kernel that takes euclidean distances and kernel\n",
        "              width as input and outputs weights in (0,1). If None, defaults to\n",
        "              an exponential kernel.\n",
        "            verbose: if true, print local prediction values from linear model\n",
        "            feature_selection: feature selection method. can be\n",
        "              'forward_selection', 'lasso_path', 'none' or 'auto'.\n",
        "              See function 'explain_instance_with_data' in lime_base.py for\n",
        "              details on what each of the options does.\n",
        "            random_state: an integer or numpy.RandomState that will be used to\n",
        "              generate random numbers. If None, the random state will be\n",
        "              initialized using the internal numpy seed.\n",
        "        \"\"\"\n",
        "        kernel_width = float(kernel_width)\n",
        "        \n",
        "        if kernel is None:\n",
        "            def kernel(d, kernel_width):\n",
        "                return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))\n",
        "        \n",
        "        kernel_fn = partial(kernel, kernel_width=kernel_width)\n",
        "        \n",
        "        self.random_state = check_random_state(random_state)\n",
        "        self.feature_selection = feature_selection\n",
        "        self.base = lime_base.LimeBase(kernel_fn, verbose, random_state=self.random_state)\n",
        "\n",
        "    def explain_instance(self, images_list, classifier_fn, labels=(1,),\n",
        "                        hide_color=None,\n",
        "                        top_labels=5, num_features=100000, num_samples=1000,\n",
        "                        batch_size=10,\n",
        "                        segments=None,\n",
        "                        distance_metric='cosine',\n",
        "                        model_regressor=None,\n",
        "                        random_seed=None):\n",
        "        \"\"\"Generates explanations for a prediction.\n",
        "        \n",
        "        First, we generate neighborhood data by randomly perturbing features\n",
        "        from the instance (see __data_inverse). We then learn locally weighted\n",
        "        linear models on this neighborhood data to explain each of the classes\n",
        "        in an interpretable way (see lime_base.py).\n",
        "        \n",
        "        Args:\n",
        "          image: 3 dimension RGB image. If this is only two dimensional,\n",
        "              we will assume it's a grayscale image and call gray2rgb.\n",
        "          classifier_fn: classifier prediction probability function, which\n",
        "              takes a numpy array and outputs prediction probabilities.  For\n",
        "              ScikitClassifiers , this is classifier.predict_proba.\n",
        "          labels: iterable with labels to be explained.\n",
        "          hide_color: TODO\n",
        "          top_labels: if not None, ignore labels and produce explanations for\n",
        "              the K labels with highest prediction probabilities, where K is\n",
        "              this parameter.\n",
        "          num_features: maximum number of features present in explanation\n",
        "          num_samples: size of the neighborhood to learn the linear model\n",
        "          batch_size: TODO\n",
        "          distance_metric: the distance metric to use for weights.\n",
        "          model_regressor: sklearn regressor to use in explanation. Defaults\n",
        "          to Ridge regression in LimeBase. Must have model_regressor.coef_\n",
        "          and 'sample_weight' as a parameter to model_regressor.fit()\n",
        "          segmentation_fn: SegmentationAlgorithm, wrapped skimage\n",
        "          segmentation function\n",
        "          random_seed: integer used as random seed for the segmentation\n",
        "              algorithm. If None, a random integer, between 0 and 1000,\n",
        "              will be generated using the internal random number generator.\n",
        "        \n",
        "        Returns:\n",
        "          An ImageExplanation object (see lime_image.py) with the corresponding\n",
        "          explanations.\n",
        "        \"\"\"\n",
        "        images = []\n",
        "        for image in images_list:\n",
        "            if len(image.shape) == 2:\n",
        "                images.append(gray2rgb(image))\n",
        "            else:\n",
        "                images.append(image)\n",
        "        \n",
        "        images = np.array(images)\n",
        "        \n",
        "        if random_seed is None:\n",
        "            random_seed = self.random_state.randint(0, high=1000)\n",
        "        \n",
        "        \"\"\"\n",
        "        if segmentation_fn is None:\n",
        "            segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=4,\n",
        "                                                  max_dist=200, ratio=0.2,\n",
        "                                                  random_seed=random_seed)\n",
        "        try:\n",
        "            segments = segmentation_fn(image)\n",
        "        except ValueError as e:\n",
        "            raise e\n",
        "        \"\"\"\n",
        "        fudged_image_list = []\n",
        "        for image in images :\n",
        "            fudged_image = image.copy()\n",
        "            if hide_color is None:\n",
        "                for x in np.unique(segments):#TODO\n",
        "                    fudged_image[segments == x] = (\n",
        "                        np.mean(image[segments == x][:, 0]),\n",
        "                        np.mean(image[segments == x][:, 1]),\n",
        "                        np.mean(image[segments == x][:, 2]))\n",
        "            else:\n",
        "                fudged_image[:] = hide_color\n",
        "            fudged_image_list.append(fudged_image)\n",
        "        \n",
        "        top = labels\n",
        "        data, labels = self.data_labels(images, fudged_image_list, segments,\n",
        "                                      classifier_fn, num_samples,\n",
        "                                      batch_size=batch_size)\n",
        "        \n",
        "        distances = sklearn.metrics.pairwise_distances(\n",
        "            data,\n",
        "            data[0].reshape(1, -1),\n",
        "            metric=distance_metric\n",
        "        ).ravel()\n",
        "        \n",
        "        \n",
        "        ret_exp = VideoExplanation(images, segments)\n",
        "        if top_labels:\n",
        "            top = np.argsort(labels[0])[-top_labels:]\n",
        "            ret_exp.top_labels = list(top)\n",
        "            ret_exp.top_labels.reverse()\n",
        "        for label in top:\n",
        "            (ret_exp.intercept[label],\n",
        "                ret_exp.local_exp[label],\n",
        "                ret_exp.score, ret_exp.local_pred) = self.base.explain_instance_with_data(\n",
        "                data, labels, distances, label, num_features,\n",
        "                model_regressor=model_regressor,\n",
        "                feature_selection=self.feature_selection)\n",
        "        return ret_exp\n",
        "        \n",
        "        #return data, labels\n",
        "\n",
        "    def data_labels(self,\n",
        "                    images,\n",
        "                    fudged_images,\n",
        "                    segments,\n",
        "                    classifier_fn,\n",
        "                    num_samples,\n",
        "                    batch_size=10):\n",
        "        \"\"\"Generates images and predictions in the neighborhood of this image.\n",
        "\n",
        "        Args:\n",
        "            image: 3d numpy array, the image\n",
        "            fudged_image: 3d numpy array, image to replace original image when\n",
        "                superpixel is turned off\n",
        "            segments: segmentation of the image\n",
        "            classifier_fn: function that takes a list of images and returns a\n",
        "                matrix of prediction probabilities\n",
        "            num_samples: size of the neighborhood to learn the linear model\n",
        "            batch_size: classifier_fn will be called on batches of this size.\n",
        "\n",
        "        Returns:\n",
        "            A tuple (data, labels), where:\n",
        "                data: dense num_samples * num_superpixels\n",
        "                labels: prediction probabilities matrix\n",
        "        \"\"\"\n",
        "        #n_features = np.unique(segments).shape[0]\n",
        "        n_features = nb_segments\n",
        "\n",
        "        data = self.random_state.randint(0, 2, num_samples * n_features)\\\n",
        "            .reshape((num_samples, n_features))\n",
        "        labels = []\n",
        "        data[0, :] = 1\n",
        "        neighboorhood = []\n",
        "        pbar = ProgressBar(num_samples)\n",
        "        pbar.start()\n",
        "        for row in data:\n",
        "            temp_img_list = copy.deepcopy(images)\n",
        "            zeros = np.where(row == 0)[0]\n",
        "            temp_2d_img_list = []\n",
        "            for i in range(len(images)):\n",
        "                mask = np.zeros(segments[i].shape).astype(bool)\n",
        "                for z in zeros:\n",
        "                    mask[segments[i] == z] = True\n",
        "                temp_img_list[i][mask] = fudged_images[i][mask]\n",
        "                temp_2d_img_list.append(rgb2gray(temp_img_list[i]))\n",
        "            neighboorhood.append(temp_2d_img_list)\n",
        "            if len(neighboorhood) == batch_size:\n",
        "                for neighboor in neighboorhood:\n",
        "                    preds = classifier_fn(Input_processing.convertImagesToClip(neighboor))\n",
        "                    labels.extend(preds)\n",
        "                neighboorhood = []\n",
        "            pbar.currval += 1\n",
        "            pbar.update()\n",
        "        pbar.finish()\n",
        "        if len(neighboorhood) > 0:\n",
        "            for neighboor in neighboorhood:\n",
        "                preds = classifier_fn(Input_processing.convertImagesToClip(neighboor))\n",
        "                labels.extend(preds)\n",
        "        return data, np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq1OGJ_7Ftnk",
        "colab_type": "text"
      },
      "source": [
        "#Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4QCkKsfFwgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classifier = Classifier(9)\n",
        "model_path = \"drive/My Drive/PRD/bestModelWts_LocMax060219.pt\"\n",
        "classifier.load_model(path_model = model_path)\n",
        "\n",
        "video_path = 'drive/My Drive/PRD/automobile-engine-rotation-velocity-master/train/500_8_1_Gly'\n",
        "input_processor = Input_processing(video_path=video_path)\n",
        "\n",
        "video_folder = input_processor.store_video_in_one_folder(31)\n",
        "print(video_folder)\n",
        "images_list = input_processor.create_images()\n",
        "\n",
        "segmenter = Segmentation()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEsg2P9OVa_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "segmenter.segment_images(video_folder)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P75VHlD8Y6hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "segments_list = segmenter.get_segments(segmentation_hierarchie = 35)\n",
        "\n",
        "explainer = LimeVideoExplainer(verbose=False)\n",
        "explanation = explainer.explain_instance(np.array(images_list), \n",
        "                                         batch_predict, # classification function\n",
        "                                         batch_size = 10,\n",
        "                                         top_labels=5, \n",
        "                                         hide_color=0,\n",
        "                                         segments = segments_list,\n",
        "                                         num_samples=10, # number of images that will be sent to classification function\n",
        "                                         random_seed=1)\n",
        "\n",
        "temps, masks = explanation.get_images_and_masks(explanation.top_labels[0], positive_only=False, num_features=1, hide_rest=False)\n",
        "for temp, mask in zip(temps,masks):\n",
        "  img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
        "  plt.figure()\n",
        "  plt.imshow(img_boundry1)\n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}